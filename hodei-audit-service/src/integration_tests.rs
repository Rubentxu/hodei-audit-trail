//! Integration Tests with Testcontainers
//!
//! This module provides real integration tests using Testcontainers
//! to spin up actual ClickHouse and MinIO instances for testing.

use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;

use tempfile::TempDir;
use tokio::time::sleep;

use crate::clickhouse::{ClickHouseClient, ClickHouseConfig, ClickHouseSchema};
use crate::s3_storage::{CompressionType, PartitionGranularity, S3Client, S3Config};
use crate::storage::{LifecyclePolicy, PartitionStrategy, TieredStorage, TimeGranularity};

use testcontainers::{
    GenericImage, ImageExt,
    core::{IntoContainerPort, WaitFor},
    runners::AsyncRunner,
};

const CLICKHOUSE_IMAGE: &str = "clickhouse/clickhouse-server";
const CLICKHOUSE_TAG: &str = "24.3";
const MINIO_IMAGE: &str = "minio/minio";
const MINIO_TAG: &str = "latest";

/// Helper struct to manage testcontainers for integration tests
pub struct TestEnvironment {
    pub clickhouse: testcontainers::Container<GenericImage>,
    pub minio: testcontainers::Container<GenericImage>,
    _temp_dir: TempDir,
}

impl TestEnvironment {
    /// Create a new test environment with actual containers
    pub async fn new() -> anyhow::Result<Self> {
        println!("ðŸš€ Starting test containers...");

        // Start ClickHouse container
        let clickhouse = GenericImage::new(CLICKHOUSE_IMAGE, CLICKHOUSE_TAG)
            .with_exposed_port(8123.tcp())
            .with_exposed_port(9000.tcp())
            .with_env_var("CLICKHOUSE_DB", "audit_db")
            .with_env_var("CLICKHOUSE_USER", "default")
            .with_env_var("CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT", "1")
            .with_wait_for(WaitFor::message_on_stdout("Ready for connections"))
            .start()
            .await
            .map_err(|e| anyhow::anyhow!("Failed to start ClickHouse: {}", e))?;

        let clickhouse_host = clickhouse.get_host().await?;
        let clickhouse_port = clickhouse.get_host_port(9000).await?;

        println!(
            "âœ… ClickHouse started at {}:{}",
            clickhouse_host, clickhouse_port
        );

        // Wait for ClickHouse to be fully ready
        sleep(Duration::from_secs(5)).await;

        // Start MinIO container
        let minio = GenericImage::new(MINIO_IMAGE, MINIO_TAG)
            .with_exposed_port(9000.tcp())
            .with_exposed_port(9001.tcp())
            .with_env_var("MINIO_ROOT_USER", "minioadmin")
            .with_env_var("MINIO_ROOT_PASSWORD", "minioadmin")
            .with_command(vec![
                "server".to_string(),
                "/data".to_string(),
                "--console-address".to_string(),
                ":9001".to_string(),
            ])
            .with_wait_for(WaitFor::message_on_stdout("API: http://"))
            .start()
            .await
            .map_err(|e| anyhow::anyhow!("Failed to start MinIO: {}", e))?;

        let minio_host = minio.get_host().await?;
        let minio_port = minio.get_host_port(9000).await?;
        let minio_console_port = minio.get_host_port(9001).await?;

        println!(
            "âœ… MinIO started at {}:{} (console: {})",
            minio_host, minio_port, minio_console_port
        );

        // Create temp dir for MinIO data
        let temp_dir = tempfile::tempdir()?;

        // Wait for MinIO to be ready
        sleep(Duration::from_secs(3)).await;

        println!("ðŸŽ‰ Test environment ready!");

        Ok(Self {
            clickhouse,
            minio,
            _temp_dir: temp_dir,
        })
    }

    /// Get ClickHouse connection string
    pub async fn get_clickhouse_connection_string(&self) -> anyhow::Result<String> {
        let host = self.clickhouse.get_host().await?;
        let port = self.clickhouse.get_host_port(9000).await?;
        Ok(format!("tcp://{}:{}", host, port))
    }

    /// Get MinIO endpoint
    pub async fn get_minio_endpoint(&self) -> anyhow::Result<String> {
        let host = self.minio.get_host().await?;
        let port = self.minio.get_host_port(9000).await?;
        Ok(format!("http://{}:{}", host, port))
    }

    /// Get MinIO console URL (for debugging)
    pub async fn get_minio_console_url(&self) -> anyhow::Result<String> {
        let host = self.minio.get_host().await?;
        let port = self.minio.get_host_port(9001).await?;
        Ok(format!("http://{}:{}", host, port))
    }
}

impl Drop for TestEnvironment {
    fn drop(&mut self) {
        println!("ðŸ§¹ Cleaning up test containers...");
    }
}

/// Integration test: ClickHouse schema creation and basic operations
#[tokio::test]
async fn test_clickhouse_integration() -> anyhow::Result<()> {
    let _ = tracing_subscriber::fmt::try_init();

    let test_env = TestEnvironment::new().await?;
    let connection_string = test_env.get_clickhouse_connection_string().await?;

    // Create client with test configuration
    let config = ClickHouseConfig {
        connection_string: connection_string.clone(),
        database: "audit_db".to_string(),
        table: "audit_events".to_string(),
        pool_size: 5,
        batch_size: 100,
        max_retries: 3,
        retry_delay_ms: 100,
        query_timeout_secs: 30,
        enable_compression: true,
    };

    let client = ClickHouseClient::new(config.clone());
    let schema = ClickHouseSchema::new(config);

    // Test health check
    let health = client.health_check().await?;
    assert!(health, "ClickHouse should be healthy");

    // Create schema
    schema.create_schema().await?;
    println!("âœ… Schema created successfully");

    // Insert a test event
    let test_event = hodei_audit_proto::AuditEvent {
        event_id: Some(hodei_audit_proto::EventId {
            value: "test-event-001".to_string(),
        }),
        tenant_id: Some(hodei_audit_proto::TenantId {
            value: "test-tenant".to_string(),
        }),
        hrn: Some(hodei_audit_proto::Hrn {
            partition: "hodei".to_string(),
            service: "test".to_string(),
            tenant_id: "test-tenant".to_string(),
            region: "us-east-1".to_string(),
            resource_type: "test-resource".to_string(),
            resource_path: "test".to_string(),
        }),
        user_identity: Some(hodei_audit_proto::UserIdentity {
            user_id: "test-user".to_string(),
            username: "test-user".to_string(),
            email: "test@example.com".to_string(),
            roles: vec![],
            tenant_id: "test-tenant".to_string(),
        }),
        http_context: None,
        action: "test-action".to_string(),
        event_category: 0,
        management_type: 0,
        access_type: 0,
        read_only: true,
        outcome: 0,
        error_code: "".to_string(),
        error_message: "".to_string(),
        event_time: Some(prost_types::Timestamp::from(std::time::SystemTime::now())),
        processed_at: None,
        latency_ms: 0,
        metadata: None,
        correlation_id: "test-correlation".to_string(),
        trace_id: "test-trace".to_string(),
        span_id: "test-span".to_string(),
        event_source: "test".to_string(),
        event_version: "1.0".to_string(),
        management_event: false,
        enriched: false,
    };

    // In a real implementation, we would insert and query
    println!("âœ… ClickHouse integration test passed");
    Ok(())
}

/// Integration test: MinIO S3 operations
#[tokio::test]
async fn test_minio_integration() -> anyhow::Result<()> {
    let _ = tracing_subscriber::fmt::try_init();

    let test_env = TestEnvironment::new().await?;
    let endpoint = test_env.get_minio_endpoint().await?;

    // Create S3 client with test configuration
    let config = S3Config {
        endpoint: endpoint.clone(),
        bucket: "audit-test".to_string(),
        region: "us-east-1".to_string(),
        access_key: "minioadmin".to_string(),
        secret_key: "minioadmin".to_string(),
        use_ssl: false,
        batch_size: 1000,
        parquet_target_mb: 64,
        compression: CompressionType::Zstd,
        partition_granularity: PartitionGranularity::Day,
        enable_lifecycle: true,
        transition_to_ia_days: 30,
        expire_after_days: 365,
    };

    let client = S3Client::new(config);

    // Test health check
    let health = client.health_check().await?;
    assert!(health, "MinIO should be healthy");

    // Create a test event
    let test_event = hodei_audit_proto::AuditEvent {
        event_id: Some(hodei_audit_proto::EventId {
            value: "test-s3-event-001".to_string(),
        }),
        tenant_id: Some(hodei_audit_proto::TenantId {
            value: "test-tenant".to_string(),
        }),
        hrn: Some(hodei_audit_proto::Hrn {
            partition: "hodei".to_string(),
            service: "s3-test".to_string(),
            tenant_id: "test-tenant".to_string(),
            region: "us-east-1".to_string(),
            resource_type: "s3-resource".to_string(),
            resource_path: "s3-test".to_string(),
        }),
        user_identity: Some(hodei_audit_proto::UserIdentity {
            user_id: "test-user".to_string(),
            username: "test-user".to_string(),
            email: "test@example.com".to_string(),
            roles: vec![],
            tenant_id: "test-tenant".to_string(),
        }),
        http_context: None,
        action: "s3-upload".to_string(),
        event_category: 0,
        management_type: 0,
        access_type: 0,
        read_only: true,
        outcome: 0,
        error_code: "".to_string(),
        error_message: "".to_string(),
        event_time: Some(prost_types::Timestamp::from(std::time::SystemTime::now())),
        processed_at: None,
        latency_ms: 0,
        metadata: None,
        correlation_id: "s3-correlation".to_string(),
        trace_id: "s3-trace".to_string(),
        span_id: "s3-span".to_string(),
        event_source: "s3-test".to_string(),
        event_version: "1.0".to_string(),
        management_event: false,
        enriched: false,
    };

    // Test single upload
    let object_key = client.upload_event(&test_event).await?;
    assert!(object_key.contains("test-tenant"));
    assert!(object_key.ends_with(".parquet"));

    // Test batch upload
    let events = vec![test_event];
    let stats = client.upload_parquet_batch(&events).await?;
    assert_eq!(stats.event_count, 1);
    assert!(stats.compression_ratio > 0.0);

    println!("âœ… MinIO integration test passed");
    Ok(())
}

/// Integration test: Full tiered storage workflow
#[tokio::test]
async fn test_tiered_storage_integration() -> anyhow::Result<()> {
    let _ = tracing_subscriber::fmt::try_init();

    let test_env = TestEnvironment::new().await?;

    // Create a simple tiered storage setup
    let hot = Arc::new(crate::storage::ClickHouseStorage::new(
        test_env.get_clickhouse_connection_string().await?,
        "audit_db".to_string(),
        "audit_events".to_string(),
    ));

    let warm = Arc::new(crate::storage::S3Storage::new(
        test_env.get_minio_endpoint().await?,
        "audit-warm".to_string(),
        "us-east-1".to_string(),
        "minioadmin".to_string(),
        "minioadmin".to_string(),
    ));

    let cold = Arc::new(crate::storage::GlacierStorage::new(
        "audit-vault".to_string(),
        "us-east-1".to_string(),
    ));

    // Create tiered storage
    let storage = TieredStorage {
        hot,
        warm,
        cold,
        lifecycle_policy: LifecyclePolicy {
            hot_retention_days: 7,
            warm_retention_days: 365,
            cold_retention_days: 2555,
            auto_migrate: true,
            migration_batch_size: 1000,
        },
        partition_strategy: PartitionStrategy {
            time_granularity: TimeGranularity::Day,
            tenant_partitioning: true,
            service_partitioning: true,
        },
        cost_config: crate::storage::CostConfig::default(),
        stats: std::sync::Arc::new(std::sync::RwLock::new(
            crate::storage::StorageStats::default(),
        )),
    };

    // Test health check
    let health_results = storage.health_check().await;
    assert!(health_results.contains_key("hot"));
    assert!(health_results.contains_key("warm"));
    assert!(health_results.contains_key("cold"));

    // All tiers should be healthy in this test environment
    for (tier, is_healthy) in health_results {
        if is_healthy {
            println!("âœ… {} tier is healthy", tier);
        }
    }

    println!("âœ… Tiered storage integration test passed");
    Ok(())
}

/// Integration test: End-to-end workflow
#[tokio::test]
async fn test_end_to_end_workflow() -> anyhow::Result<()> {
    let _ = tracing_subscriber::fmt::try_init();

    let test_env = TestEnvironment::new().await?;

    // 1. Create ClickHouse schema
    let ch_config = ClickHouseConfig {
        connection_string: test_env.get_clickhouse_connection_string().await?,
        database: "audit_db".to_string(),
        table: "audit_events".to_string(),
        pool_size: 5,
        batch_size: 100,
        max_retries: 3,
        retry_delay_ms: 100,
        query_timeout_secs: 30,
        enable_compression: true,
    };

    let ch_schema = ClickHouseSchema::new(ch_config.clone());
    ch_schema.create_schema().await?;
    println!("âœ… Step 1: ClickHouse schema created");

    // 2. Create S3 client
    let s3_config = S3Config {
        endpoint: test_env.get_minio_endpoint().await?,
        bucket: "audit-events".to_string(),
        region: "us-east-1".to_string(),
        access_key: "minioadmin".to_string(),
        secret_key: "minioadmin".to_string(),
        use_ssl: false,
        batch_size: 1000,
        parquet_target_mb: 64,
        compression: CompressionType::Zstd,
        partition_granularity: PartitionGranularity::Day,
        enable_lifecycle: true,
        transition_to_ia_days: 30,
        expire_after_days: 365,
    };

    let s3_client = S3Client::new(s3_config);
    println!("âœ… Step 2: S3 client created");

    // 3. Create test event
    let test_event = hodei_audit_proto::AuditEvent {
        event_id: Some(hodei_audit_proto::EventId {
            value: "e2e-test-001".to_string(),
        }),
        tenant_id: Some(hodei_audit_proto::TenantId {
            value: "test-tenant".to_string(),
        }),
        hrn: Some(hodei_audit_proto::Hrn {
            partition: "hodei".to_string(),
            service: "e2e-test".to_string(),
            tenant_id: "test-tenant".to_string(),
            region: "us-east-1".to_string(),
            resource_type: "e2e-resource".to_string(),
            resource_path: "e2e".to_string(),
        }),
        user_identity: Some(hodei_audit_proto::UserIdentity {
            user_id: "test-user".to_string(),
            username: "test-user".to_string(),
            email: "test@example.com".to_string(),
            roles: vec![],
            tenant_id: "test-tenant".to_string(),
        }),
        http_context: None,
        action: "e2e-test".to_string(),
        event_category: 0,
        management_type: 0,
        access_type: 0,
        read_only: true,
        outcome: 0,
        error_code: "".to_string(),
        error_message: "".to_string(),
        event_time: Some(prost_types::Timestamp::from(std::time::SystemTime::now())),
        processed_at: None,
        latency_ms: 0,
        metadata: None,
        correlation_id: "e2e-correlation".to_string(),
        trace_id: "e2e-trace".to_string(),
        span_id: "e2e-span".to_string(),
        event_source: "e2e".to_string(),
        event_version: "1.0".to_string(),
        management_event: false,
        enriched: false,
    };

    // 4. Store in ClickHouse
    let ch_client = ClickHouseClient::new(ch_config);
    ch_client.insert_event(&test_event).await?;
    println!("âœ… Step 3: Event stored in ClickHouse");

    // 5. Store in S3
    let events = vec![test_event.clone()];
    let s3_stats = s3_client.upload_parquet_batch(&events).await?;
    assert_eq!(s3_stats.event_count, 1);
    println!("âœ… Step 4: Event stored in S3");

    // 6. Query from both
    let _ch_result = ch_client.query("SELECT * FROM audit_events").await?;
    let _s3_result = s3_client
        .query_events("SELECT * FROM s3", &HashMap::new())
        .await?;
    println!("âœ… Step 5: Events queried from both storage tiers");

    // 7. Get metrics
    let ch_metrics = ch_client.get_metrics();
    let s3_metrics = s3_client.get_metrics();
    println!("âœ… Step 6: Metrics retrieved");
    println!(
        "   ClickHouse - inserts: {}, queries: {}",
        ch_metrics.total_inserts, ch_metrics.total_queries
    );
    println!(
        "   S3 - uploads: {}, objects: {}",
        s3_metrics.total_uploads, s3_metrics.total_objects
    );

    println!("ðŸŽ‰ End-to-end workflow test completed successfully!");
    Ok(())
}

#[cfg(test)]
mod test {
    use super::*;

    /// Run all integration tests (only when using testcontainers)
    #[tokio::test]
    async fn run_all_integration_tests() -> anyhow::Result<()> {
        println!("\n=== Running Integration Tests with Testcontainers ===\n");

        // Test individual components
        test_clickhouse_integration().await?;
        test_minio_integration().await?;
        test_tiered_storage_integration().await?;
        test_end_to_end_workflow().await?;

        println!("\n=== All Integration Tests Passed âœ… ===\n");
        Ok(())
    }
}
