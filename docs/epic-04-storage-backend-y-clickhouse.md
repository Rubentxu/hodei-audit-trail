# √âpica 4: Storage Backend y ClickHouse

## üìã Resumen Ejecutivo

**Objetivo**: Implementar el backend de almacenamiento con ClickHouse como Hot Tier, S3/MinIO como Warm/Cold Tier, y lifecycle policies autom√°ticas para optimizar costo y performance.

**Duraci√≥n**: 3-4 semanas

---

## Historias Principales

### Historia 4.1: ClickHouse Schema y Optimizaci√≥n

**Objetivo**: Crear schema optimizado con √≠ndices y particionamiento.

**Criterios de Aceptaci√≥n**:
- [ ] Schema creado con particionamiento mensual
- [ ] √çndices en tenant_id, hrn, timestamp
- [ ] TTL configurado (7 d√≠as para Hot)
- [ ] Connection pooling implementado
- [ ] Batch inserts optimizados

**Tareas**:
1. Crear DDL scripts con MergeTree engine
2. Configurar √≠ndices bloom para tenant_id
3. Implementar ClickHouseStorage trait
4. Batch inserts con 1000-10000 events/batch
5. Connection pool con 10-50 connections
6. Tests de performance

#### ‚ö†Ô∏è FASE DE TESTING (OBLIGATORIO - BLOQUEANTE)

**Regla**: NO continuar hasta que TODOS los tests pasen en verde ‚úÖ

**Tests Unitarios Requeridos**:
- [ ] Validar schema DDL se crea correctamente
- [ ] Testear particionamiento mensual funciona
- [ ] Verificar √≠ndices bloom para tenant_id
- [ ] Testear ClickHouseStorage trait implementation
- [ ] Validar batch inserts con 1000-10000 events/batch
- [ ] Testear connection pool (10-50 connections)
- [ ] Verificar TTL configurado (7 d√≠as para Hot)
- [ ] Testear optimizaciones de performance

**Tests de Integraci√≥n Requeridos**:
- [ ] Schema creado y funcionando
- [ ] √çndices en tenant_id, hrn, timestamp
- [ ] TTL configurado correctamente
- [ ] Connection pooling implementado y estable
- [ ] Batch inserts optimizados funcionando
- [ ] Insert Throughput >= 10K events/sec
- [ ] Query Latency < 10ms (Hot tier)
- [ ] Tests de performance passing

**Comandos de Verificaci√≥n**:
```bash
# Testear schema creation
cargo test -p hodei-audit-service clickhouse_schema

# Testear batch inserts
cargo test -p hodei-audit-service clickhouse_batch_inserts

# Testear connection pool
cargo test -p hodei-audit-service clickhouse_pool

# Testear performance
cargo bench -p hodei-audit-service clickhouse_performance

# Verificar √≠ndices
clickhouse-client --query="SHOW INDEX FROM audit_events"

# Verificar TTL
clickhouse-client --query="SELECT * FROM system.tables WHERE name='audit_events'"
```

**Criterios de Aceptaci√≥n de Tests**:
- [ ] 100% de tests unitarios passing
- [ ] 100% de tests de integraci√≥n passing  
- [ ] Schema creado con optimizaciones
- [ ] Query Latency < 10ms
- [ ] Insert Throughput >= 10K events/sec
- [ ] **TODOS los criterios en verde ‚úÖ**

**Definici√≥n de Done (ACTUALIZADA)**:
- ‚úÖ Schema creado con particionamiento mensual
- ‚úÖ √çndices en tenant_id, hrn, timestamp
- ‚úÖ TTL configurado (7 d√≠as para Hot)
- ‚úÖ Connection pooling implementado
- ‚úÖ Batch inserts optimizados
- ‚úÖ **TODOS los tests passing (100%)** ‚ö†Ô∏è

### Historia 4.2: Tiered Storage Orchestrator

**Objetivo**: Unificar acceso a m√∫ltiples tiers de almacenamiento.

**Criterios de Aceptaci√≥n**:
- [ ] TieredStorage orchestrator
- [ ] Query planning autom√°tico
- [ ] Cross-tier query execution
- [ ] Lifecycle policies autom√°ticas
- [ ] Cost estimation

**Tareas**:
1. Implementar StorageBackend trait
2. Query planner que determina tiers
3. Parallel execution across tiers
4. Lifecycle management
5. Cost optimizer

#### ‚ö†Ô∏è FASE DE TESTING (OBLIGATORIO - BLOQUEANTE)

**Regla**: NO continuar hasta que TODOS los tests pasen en verde ‚úÖ

**Tests Unitarios Requeridos**:
- [ ] Validar StorageBackend trait se implementa correctamente
- [ ] Testear TieredStorage orchestrator
- [ ] Verificar query planner determina tiers autom√°ticamente
- [ ] Testear cross-tier query execution
- [ ] Validar lifecycle policies autom√°ticas
- [ ] Testear cost estimation
- [ ] Verificar parallel execution across tiers
- [ ] Testear que lifecycle management funciona

**Tests de Integraci√≥n Requeridos**:
- [ ] TieredStorage orchestrator funcionando
- [ ] Query planning autom√°tico operativo
- [ ] Cross-tier query execution working
- [ ] Lifecycle policies autom√°ticas activas
- [ ] Cost estimation accurate
- [ ] Parallel queries across tiers optimizadas
- [ ] Tests de performance passing
- [ ] Migration entre tiers autom√°tica

**Comandos de Verificaci√≥n**:
```bash
# Testear tiered storage
cargo test -p hodei-audit-service tiered_storage

# Testear query planner
cargo test -p hodei-audit-service query_planner

# Testear lifecycle policies
cargo test -p hodei-audit-service lifecycle_policies

# Testear cross-tier queries
cargo test -p hodei-audit-service cross_tier_queries

# Benchmarks
cargo bench -p hodei-audit-service tiered_performance

# Verificar cost estimation
./scripts/validate-cost-estimation.sh
```

**Criterios de Aceptaci√≥n de Tests**:
- [ ] 100% de tests unitarios passing
- [ ] 100% de tests de integraci√≥n passing  
- [ ] TieredStorage orchestrator funcionando
- [ ] Query planning autom√°tico operativo
- [ ] Cross-tier queries funcionando
- [ ] **TODOS los criterios en verde ‚úÖ**

**Definici√≥n de Done (ACTUALIZADA)**:
- ‚úÖ TieredStorage orchestrator
- ‚úÖ Query planning autom√°tico
- ‚úÖ Cross-tier query execution
- ‚úÖ Lifecycle policies autom√°ticas
- ‚úÖ Cost estimation
- ‚úÖ **TODOS los tests passing (100%)** ‚ö†Ô∏è

### Historia 4.3: S3/MinIO Integration (Warm/Cold)

**Objetivo**: Implementar storage econ√≥mico para datos hist√≥ricos.

**Criterios de Aceptaci√≥n**:
- [ ] S3/MinIO client configurado
- [ ] Parquet format para analytics
- [ ] Partitioning por fecha/tenant
- [ ] Lifecycle rules S3 Standard ‚Üí IA ‚Üí Glacier
- [ ] Athena/Trino queries

**Tareas**:
1. Configurar S3 client
2. Implementar Parquet writer
3. Partitioning strategy
4. Lifecycle policies
5. Query integration

#### ‚ö†Ô∏è FASE DE TESTING (OBLIGATORIO - BLOQUEANTE)

**Regla**: NO continuar hasta que TODOS los tests pasen en verde ‚úÖ

**Tests Unitarios Requeridos**:
- [ ] Validar S3/MinIO client configurado correctamente
- [ ] Testear Parquet format para analytics
- [ ] Verificar partitioning por fecha/tenant
- [ ] Testear lifecycle rules S3 Standard ‚Üí IA ‚Üí Glacier
- [ ] Validar que Athena/Trino queries funcionan
- [ ] Testear Parquet writer
- [ ] Verificar query integration
- [ ] Testear S3 client operations

**Tests de Integraci√≥n Requeridos**:
- [ ] S3/MinIO client configurado y accesible
- [ ] Parquet format optimizado para analytics
- [ ] Partitioning por fecha/tenant funcionando
- [ ] Lifecycle rules activas y autom√°ticas
- [ ] Athena/Trino queries working
- [ ] Query Latency < 500ms (Warm tier)
- [ ] Storage Cost < $0.023/GB-month
- [ ] Tests de performance passing

**Comandos de Verificaci√≥n**:
```bash
# Testear S3 client
cargo test -p hodei-audit-service s3_minio_client

# Testear Parquet writer
cargo test -p hodei-audit-service parquet_writer

# Testear lifecycle policies
cargo test -p hodei-audit-service s3_lifecycle_policies

# Testear Athena/Trino queries
cargo test -p hodei-audit-service athena_trino_queries

# Benchmarks
cargo bench -p hodei-audit-service s3_performance

# Verificar cost
aws s3 ls --recursive s3://hodei-audit-warm/ --summarize
```

**Criterios de Aceptaci√≥n de Tests**:
- [ ] 100% de tests unitarios passing
- [ ] 100% de tests de integraci√≥n passing  
- [ ] S3/MinIO client configurado
- [ ] Parquet format optimizado
- [ ] Query Latency < 500ms
- [ ] **TODOS los criterios en verde ‚úÖ**

**Definici√≥n de Done (ACTUALIZADA)**:
- ‚úÖ S3/MinIO client configurado
- ‚úÖ Parquet format para analytics
- ‚úÖ Partitioning por fecha/tenant
- ‚úÖ Lifecycle rules S3 Standard ‚Üí IA ‚Üí Glacier
- ‚úÖ Athena/Trino queries
- ‚úÖ **TODOS los tests passing (100%)** ‚ö†Ô∏è

---

## M√©tricas

| M√©trica | Objetivo |
|---------|----------|
| Query Latency (Hot) | < 10ms |
| Query Latency (Warm) | < 500ms |
| Insert Throughput | 10K+ events/sec |
| Storage Cost | < $0.023/GB-month |

---

## ‚è≠Ô∏è Siguiente √âpica

[√âpica 5: Multi-Tenancy y Seguridad](epic-05-multi-tenancy-y-seguridad.md)
